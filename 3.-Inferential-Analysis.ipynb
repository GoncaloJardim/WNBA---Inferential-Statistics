{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics\n",
    "## Part III - Inferential Analysis\n",
    "\n",
    "We're now going to look for answers to the ongoing basketball discussions between you and your family. The main ones we want to reasearch are the following:\n",
    "\n",
    "- Your grandmother says that your sister couldn't play in a professional basketball league (not only the WNBA, but ANY professional basketball league) because she's too skinny and lacks muscle.\n",
    "- Your sister says that most female professional players fail their free throws.\n",
    "- Your brother-in-law heard on the TV that the average assists among NBA (male) and WNBA (female) players is 52 for the 2016-2017 season. He is convinced this average would be higher if we only considered the players from the WNBA.\n",
    "\n",
    "Let's investigate these claims and see if we can find proof to refute or support them.\n",
    "\n",
    "### Libraries\n",
    "Import the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import ttest_1samp\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Load the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Birth_Place</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Age</th>\n",
       "      <th>College</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Games Played</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aerial Powers</td>\n",
       "      <td>DAL</td>\n",
       "      <td>F</td>\n",
       "      <td>183</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.200991</td>\n",
       "      <td>US</td>\n",
       "      <td>January 17, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>37.5</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>80.8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alana Beard</td>\n",
       "      <td>LA</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>73.0</td>\n",
       "      <td>21.329438</td>\n",
       "      <td>US</td>\n",
       "      <td>May 14, 1982</td>\n",
       "      <td>35</td>\n",
       "      <td>Duke</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>947</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>50.8</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alex Bentley</td>\n",
       "      <td>CON</td>\n",
       "      <td>G</td>\n",
       "      <td>170</td>\n",
       "      <td>69.0</td>\n",
       "      <td>23.875433</td>\n",
       "      <td>US</td>\n",
       "      <td>October 27, 1990</td>\n",
       "      <td>26</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>617</td>\n",
       "      <td>82</td>\n",
       "      <td>218</td>\n",
       "      <td>37.6</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>29.7</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>83.3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Alex Montgomery</td>\n",
       "      <td>SAN</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>84.0</td>\n",
       "      <td>24.543462</td>\n",
       "      <td>US</td>\n",
       "      <td>December 11, 1988</td>\n",
       "      <td>28</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>721</td>\n",
       "      <td>75</td>\n",
       "      <td>195</td>\n",
       "      <td>38.5</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>30.9</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>81.0</td>\n",
       "      <td>35</td>\n",
       "      <td>134</td>\n",
       "      <td>169</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alexis Jones</td>\n",
       "      <td>MIN</td>\n",
       "      <td>G</td>\n",
       "      <td>175</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.469388</td>\n",
       "      <td>US</td>\n",
       "      <td>August 5, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>R</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Name Team  Pos  Height  Weight        BMI  \\\n",
       "0           0    Aerial Powers  DAL    F     183    71.0  21.200991   \n",
       "1           1      Alana Beard   LA  G/F     185    73.0  21.329438   \n",
       "2           2     Alex Bentley  CON    G     170    69.0  23.875433   \n",
       "3           3  Alex Montgomery  SAN  G/F     185    84.0  24.543462   \n",
       "4           4     Alexis Jones  MIN    G     175    78.0  25.469388   \n",
       "\n",
       "  Birth_Place          Birthdate  Age         College Experience  \\\n",
       "0          US   January 17, 1994   23  Michigan State          2   \n",
       "1          US       May 14, 1982   35            Duke         12   \n",
       "2          US   October 27, 1990   26      Penn State          4   \n",
       "3          US  December 11, 1988   28    Georgia Tech          6   \n",
       "4          US     August 5, 1994   23          Baylor          R   \n",
       "\n",
       "   Games Played  MIN  FGM  FGA   FG%  3PM  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0             8  173   30   85  35.3   12   32  37.5   21   26  80.8     6   \n",
       "1            30  947   90  177  50.8    5   18  27.8   32   41  78.0    19   \n",
       "2            26  617   82  218  37.6   19   64  29.7   35   42  83.3     4   \n",
       "3            31  721   75  195  38.5   21   68  30.9   17   21  81.0    35   \n",
       "4            24  137   16   50  32.0    7   20  35.0   11   12  91.7     3   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TO  PTS  DD2  TD3  \n",
       "0    22   28   12    3    6  12   93    0    0  \n",
       "1    82  101   72   63   13  40  217    0    0  \n",
       "2    36   40   78   22    3  24  218    0    0  \n",
       "3   134  169   65   20   10  38  188    2    0  \n",
       "4     9   12   12    7    0  14   50    0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "wnba= pd.read_csv(r\"C:\\Users\\crocs\\OneDrive - Universidade de Lisboa\\Ambiente de Trabalho\\Gon√ßalo\\College&Courses\\Data Analytics- IronHack\\Course Data Analytics\\Labs\\Week5\\M2-mini-project2\\your-code\\wnba_clean.csv\")\n",
    "wnba.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Can my sister play in a professional female basketball league?\n",
    "\n",
    "As we said, you grandmother is convinced that your sister couldn't play in a professional league because of her physique and weight (her weight is 67kg). \n",
    "\n",
    "To find an actual answer to the question we first need to know what's the average weight of a professional female basketball player. The data we have only refers to the WNBA league and not to every female professional basketball league in the world, therefore we have no way of actually calculating it.\n",
    "\n",
    "Still, given that we do have *some* data we can **infer** it using a sample of players like the one we have. \n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the average weight. Do you feel it actually fulfills those requirements? Do you need to make any assumptions? We could calculate a confidence interval to do the inference, but do you know any other ways?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n",
      "113.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Birth_Place</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Age</th>\n",
       "      <th>College</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Games Played</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Moriah Jefferson</td>\n",
       "      <td>SAN</td>\n",
       "      <td>G</td>\n",
       "      <td>168</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.486961</td>\n",
       "      <td>US</td>\n",
       "      <td>August 3, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>514</td>\n",
       "      <td>81</td>\n",
       "      <td>155</td>\n",
       "      <td>52.3</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>74.1</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>92</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0              Name Team Pos  Height  Weight        BMI  \\\n",
       "96          97  Moriah Jefferson  SAN   G     168    55.0  19.486961   \n",
       "\n",
       "   Birth_Place       Birthdate  Age      College Experience  Games Played  \\\n",
       "96          US  August 3, 1994   23  Connecticut          1            21   \n",
       "\n",
       "    MIN  FGM  FGA   FG%  3PM  3PA   3P%  FTM  FTA   FT%  OREB  DREB  REB  AST  \\\n",
       "96  514   81  155  52.3    9   20  45.0   20   27  74.1     6    31   37   92   \n",
       "\n",
       "    STL  BLK  TO  PTS  DD2  TD3  \n",
       "96   33    2  43  191    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "\n",
    "\n",
    "#extra notes:\n",
    "print(wnba[\"Weight\"].min())\n",
    "print(wnba[\"Weight\"].max())\n",
    "wnba[wnba[\"Weight\"] == wnba[\"Weight\"].min()]\n",
    "\n",
    "#Just to check we can see that there's a player called Moriah Jefferson which is 168 cm and as a weight of 55KG, inferior to the sister"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the average weight with a confidence level of 95%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.996110408297898\n",
      "78.97887323943662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.1290320537029, 80.82871442517035)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "mean = wnba[\"Weight\"].mean()\n",
    "std =  wnba[\"Weight\"].std(ddof = 1)\n",
    "print(std)\n",
    "print(mean)\n",
    "n = len(wnba[\"Weight\"])\n",
    "st.norm.interval(0.955, loc = mean, scale = std/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you say about these results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "#For a 95% confidence interval, the weight of wnba players in this sample dataframe are in the range from 77.18 to 80.8221\n",
    "# Since our sample is only from wnba players the confidence interval for the mean of weight of basketball players is really close to the sample mean, because we used a bias sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your sister weighs 67kg what would you tell your grandmother in regards to her assumption?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "#I would say that unfortunately she doen's have enough weight to be in a women  basketball league "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Can you plot the probability distribution of the average weight, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Do female professional basketball players fail the majority of their free throws?\n",
    "\n",
    "You do not agree with your sister when she says that most female players fail their free throws. You decide to try and estimate the percentage of players that fail more than 40% of their free throws using, you guessed it, the WNBA sample.\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the proportion of players that miss more than 40% of their free throws. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.53615053714203\n",
      "7.049350845191532e-19\n",
      "-10.175942061238205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "\n",
    "#STEP 1:\n",
    "#Define hypotesis:\n",
    "\n",
    "    #H0: mu(FT) >= 40%\n",
    "    #H1: mu(FT) < 40%\n",
    "    \n",
    "#STEP 2:\n",
    "#Confidence level:\n",
    "alpha = 0.05\n",
    "wnba[\"FT_miss\"] = 100 - wnba[\"FT%\"]\n",
    "#STEP 3:\n",
    "    #Getting the sample\n",
    "wnba_sample = wnba[\"FT_miss\"]\n",
    "\n",
    "#STEP 4:\n",
    "    #Compute Statistic:\n",
    "mean = wnba_sample.mean()\n",
    "std = wnba_sample.std(ddof = 1)\n",
    "print(std)\n",
    "n = len(wnba[\"FT_miss\"])\n",
    "\n",
    "#STEP 5:\n",
    "    #Getting the p-value:\n",
    "stat = (mean - 40)/(std/ np.sqrt(n))\n",
    "p_value = st.t.sf(abs(stat),n-1)\n",
    "print(p_value)\n",
    "print(stat)\n",
    "\n",
    "#STEP 6:\n",
    "    #DECIDING:\n",
    "    \n",
    "\n",
    "\n",
    "#Since p_value is lower than alpha we do not reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the proportion with a confidence level of 95%:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.53615053714203\n",
      "24.171126760563386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21.05284825885878, 27.28940526226799)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# mean = wnba[\"FT%\"].mean()\n",
    "# std =  wnba[\"FT%\"].std(ddof = 1)\n",
    "# print(std)\n",
    "# print(mean)\n",
    "# n = len(wnba[\"FT%\"])\n",
    "# st.norm.interval(0.955, loc = mean, scale = std/np.sqrt(n))\n",
    "\n",
    "\n",
    "\n",
    "mean = wnba[\"FT_miss\"].mean()\n",
    "std =  wnba[\"FT_miss\"].std(ddof = 1)\n",
    "print(std)\n",
    "print(mean)\n",
    "n = len(wnba[\"FT_miss\"])\n",
    "st.norm.interval(0.955, loc = mean, scale = std/np.sqrt(n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you comment about our result? What would you tell your sister?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "#WE can tell that her guess werer wrong and the mean percentage of FT% made are actually between (72.710594737732, 78.94715174114121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the probability distribution of the proportion of missed free throws, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Is the average number of assists for WNBA players only higher than the average for WNBA and NBA players together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your brother-in-law is convinced that the average assists for female professional players is higher than the average of both female and male players combined (which is 52 for the 2016-2017 season). You would like to actually prove if this is true or not but you remember your stats teacher saying \"you can't *prove* anything, you just can say that *you are not* saying foolishness\".\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to do that. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.25704225352113\n",
      "-1.0749973596241449\n",
      "0.2842120087491155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your-answer-here\n",
    "\n",
    "mean_manwoman = (wnba[\"AST\"].mean() + 52) / 2\n",
    "print(mean_manwoman)\n",
    "\n",
    "#STEP 1:\n",
    "#Define hypotesis:\n",
    "\n",
    "    #H0: mu(AST) <=  48.257\n",
    "    #H1: mu(AST) > 48.257\n",
    "    \n",
    "#STEP 2:\n",
    "#Confidence level:\n",
    "alpha = 0.05\n",
    "\n",
    "#STEP 3:\n",
    "    #Getting the sample\n",
    "wnba_sample = wnba[\"AST\"]\n",
    "\n",
    "#STEP 4:\n",
    "    #Compute Statistic:\n",
    "mean = wnba_sample.mean()\n",
    "std = wnba_sample.std(ddof = 1)\n",
    "n = len(wnba[\"AST\"])\n",
    "\n",
    "#STEP 5:\n",
    "    #Getting the p-value:\n",
    "stat = (mean - mean_manwoman)/(std/ np.sqrt(n))\n",
    "p_value = st.t.sf(abs(stat),n-1)*2\n",
    "print(stat)\n",
    "print(p_value)\n",
    "\n",
    "#STEP 6:\n",
    "    #DECIDING:\n",
    "    \n",
    "p_value < alpha\n",
    "\n",
    "#Since p_value is higher than alpha we do not reject H0 hypotesis where woman average assist is lower than the combined average of woman and man average assists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a two-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "#We do not reject the H0 hypotesis since p_value is higher than alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now use a one-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.25704225352113\n",
      "0.14210600437455775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your-answer-here\n",
    "\n",
    "#your-answer-here\n",
    "\n",
    "mean_manwoman = (wnba[\"AST\"].mean() + 52) / 2\n",
    "print(mean_manwoman)\n",
    "\n",
    "#STEP 1:\n",
    "#Define hypotesis:\n",
    "\n",
    "    #H0: mu(AST) <=  48.257\n",
    "    #H1: mu(FT) > 48.257\n",
    "    \n",
    "#STEP 2:\n",
    "#Confidence level:\n",
    "alpha = 0.05\n",
    "\n",
    "#STEP 3:\n",
    "    #Getting the sample\n",
    "wnba_sample = wnba[\"AST\"]\n",
    "\n",
    "#STEP 4:\n",
    "    #Compute Statistic:\n",
    "mean = wnba_sample.mean()\n",
    "std = wnba_sample.std(ddof = 1)\n",
    "n = len(wnba[\"AST\"])\n",
    "\n",
    "#STEP 5:\n",
    "    #Getting the p-value:\n",
    "stat = (mean - mean_manwoman)/(std/ np.sqrt(n))\n",
    "p_value = st.t.sf(abs(stat),n-1)\n",
    "print(p_value)\n",
    "\n",
    "#STEP 6:\n",
    "    #DECIDING:\n",
    "    \n",
    "p_value < alpha\n",
    "\n",
    "#Since p_value is higher than alpha we still do not reject H0 hypotesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the resulting t-distribution of both tests? Indicate where the is the critical region and where does your statistic fall.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Satisfying your curiosity\n",
    "\n",
    "You finally managed to solve your family's debates over basketball! While you were doing that you started to take an interest in the normal distribution.\n",
    "\n",
    "You read that the normal distribution is present in a lot of natural phenomenons, like blood pressure, IQ, weight and height. If, for example, we could plot the distribution of the weights of every human on the planet right now it would have the shape of a normal distribution.\n",
    "\n",
    "In light of this you would like to see if it's possible to check if the distribution of the weights of the WNBA players is a sample distribution that comes from a population that has a normal distribution, because theoretically this should be the case.\n",
    "\n",
    "**How would you try to demonstrate that our sample fits a normal distribution? What kind of test would you use? Would you have to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are your comments in regards to the results of the test?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
